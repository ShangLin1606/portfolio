# ğŸ“° news-summarizer-tw â€” Traditional Chinese News Summarization Pipelineï¼ˆç¹ä¸­æ–°èæ‘˜è¦å…¨æµç¨‹ï¼‰
**GitHub Repo:** [ğŸ”— Open Project](https://github.com/ShangLin1606/news-summarizer-tw)

This project provides a **modular NLP pipeline** to clean, convert, summarize, and evaluate Chinese (Traditional) news articles.  
æœ¬å°ˆæ¡ˆä»¥å¤šéšæ®µè¨­è¨ˆï¼Œæ¶µè“‹ã€Œè³‡æ–™æ²»ç† â†’ ç°¡è½‰ç¹ â†’ æ–‡å­—æ¸…ç† â†’ æ‘˜è¦ç”Ÿæˆ â†’ æŒ‡æ¨™è©•ä¼° â†’ è³‡æ–™é›†åˆ‡åˆ† â†’ è¨“ç·´ã€çš„å®Œæ•´æµç¨‹ï¼Œé©ç”¨æ–¼ç ”ç©¶èˆ‡å¯¦ä½œè½åœ°ã€‚

---

## ğŸ§© Overview
The pipeline standardizes raw news data, converts Simplified to Traditional Chinese, performs text cleaning, and generates summaries via an LLM/model abstraction.  
çµæœå¯é€é **BERTScore/ROUGE** ç­‰æŒ‡æ¨™è©•ä¼°ï¼Œä¸¦è¼¸å‡ºå¯é‡ç¾çš„å ±è¡¨èˆ‡è³‡æ–™é›†ï¼Œä¾¿æ–¼å¾ŒçºŒæ¨¡å‹è¨“ç·´èˆ‡æ¯”è¼ƒã€‚

**Dataset**: Kaggle â€” *Categorised News Dataset from Fudan University*ï¼ˆè«‹ä¾å…¶æˆæ¬Šæ¢æ¬¾ä½¿ç”¨èˆ‡å¼•ç”¨ï¼‰

---

## ğŸš€ Objectives
- Build a **scalable, stage-based pipeline** for Chinese news summarization.  
- Provide a **unified model interface** to switch between cloud LLMs and local Transformer models.  
- Offer **reproducible metrics and artifacts** (reports, summaries, datasets) for experiments and benchmarking.

---

## ğŸ§  Architecture

Raw News â†’ Folder Restructure â†’ S2T Conversion â†’ Text Cleaning â†’ Statistics â†’ Summarizationï¼ˆLLM Wrapperï¼‰â†’ Evaluationï¼ˆBERTScore/ROUGEï¼‰â†’ Dataset Prep â†’ (Optional) Model Training

---

## ğŸ’¡ Key Features
- **8-Stage Pipeline**: `stage01`â€“`stage08` å°æ‡‰æ¸…æ¥šï¼›å¯å–®ç¨æˆ–ä¸²è¡ŒåŸ·è¡Œã€‚  
- **ç¹é«”ä¸­æ–‡å‹å–„**ï¼šStage 02 å…§å»ºç°¡è½‰ç¹ï¼ˆS2Tï¼‰ï¼Œé©é…è‡ºç£ç”¨å­—ã€‚  
- **Model Abstraction**ï¼š`models/llm_model.py` å°è£ `summarize()` ä»‹é¢ï¼Œè¼•é¬†åˆ‡æ› LLM/æœ¬åœ°æ¨¡å‹ã€‚  
- **Evaluation-Ready**ï¼šStage 06 æä¾› BERTScoreï¼›å¯å»¶ä¼¸ ROUGEã€BLEURT èˆ‡äººè©•æµç¨‹ã€‚  
- **Reproducible Outputs**ï¼šç”¢ç”Ÿçµ±è¨ˆå ±è¡¨ã€æ‘˜è¦çµæœèˆ‡è³‡æ–™é›†åˆ‡åˆ†ï¼Œæ–¹ä¾¿ç‰ˆæœ¬åŒ–èˆ‡æ¯”è¼ƒã€‚

---

## ğŸ§ª Results & Deliverables
- **Artifacts**ï¼š
  - æ¸…ç†å¾Œæ–‡æœ¬èˆ‡æ‘˜è¦æª”ï¼ˆåˆ†éšæ®µè¼¸å‡ºï¼‰  
  - çµ±è¨ˆå ±è¡¨ï¼ˆé•·åº¦åˆ†ä½ˆã€è©é »ç­‰ï¼‰èˆ‡è©•ä¼°çµæœï¼ˆBERTScore/ROUGEï¼‰  
  - å¯ç›´æ¥è¨“ç·´çš„è³‡æ–™é›†ï¼ˆtrain/valid/testï¼‰
- **Qualitative Outcomes**ï¼šæ•´é«”æ‘˜è¦æ›´èšç„¦ã€å†—è©é›œè¨Šä¸‹é™ã€é•·æ–‡è™•ç†æ›´ç©©å®šï¼ˆå¯æ­é…åˆ‡ç‰‡/RAG å¼·åŒ–ï¼‰ã€‚

> è¨»ï¼šæŒ‡æ¨™æˆæ•ˆæœƒä¾è³‡æ–™é¸å–ã€é è™•ç†ç­–ç•¥èˆ‡æ‰€é¸æ¨¡å‹è€Œç•°ã€‚

---

## ğŸ‘¤ My Contributions
- è¦åŠƒèˆ‡å¯¦ä½œ **8 éšæ®µæ¨¡çµ„åŒ– Pipeline**ï¼Œå¼·èª¿å¯ç¶­è­·æ€§èˆ‡æ“´å……æ€§ã€‚  
- è¨­è¨ˆ **LLM/Transformer çµ±ä¸€æ¥å£**ï¼Œæ”¯æ´é›²ç«¯èˆ‡æœ¬åœ°æ¨¡å‹å¿«é€Ÿåˆ‡æ›ã€‚  
- è£½ä½œ **çµ±è¨ˆ/è©•ä¼°å ±è¡¨è¼¸å‡º** èˆ‡è³‡æ–™å¤¾è¦ç¯„ï¼Œæå‡é‡ç¾æ€§èˆ‡åœ˜éšŠå”ä½œæ•ˆç‡ã€‚

---

## ğŸ§° Tech Stack
Python â€¢ Transformers â€¢ PyTorch â€¢ bert-score â€¢ OpenCC â€¢ Jieba / Tokenization â€¢ Pandas / Polars â€¢ Matplotlib  
(Optional) Flask / FastAPI for service endpoints; ROUGE / BLEURT for additional metrics

---

## ğŸ“¦ Dataset
- **Kaggle**: *Categorised News Dataset from Fudan University*ï¼ˆè«‹è‡³ Kaggle ä¸‹è¼‰ä¸¦éµå¾ªå…¶æˆæ¬Šæ¢æ¬¾ï¼‰  
- å»ºè­°å°‡åŸå§‹è³‡æ–™ç½®æ–¼ `data/raw/`ï¼Œå…¶é¤˜éšæ®µè¼¸å‡ºä¾åºæ”¾æ–¼ `data/01_restructured/`ã€`data/02_trad/`ã€`data/03_clean/`â€¦ ç­‰ç›®éŒ„ã€‚

---

## ğŸ§­ How to Run (Stages)
```bash
# 01 ç›®éŒ„é‡æ•´
python stage01_preprocess_folder_restructure.py --src data/raw --dst data/01_restructured

# 02 ç°¡è½‰ç¹
python stage02_text_convert_s2t.py --src data/01_restructured --dst data/02_trad

# 03 æ–‡å­—æ¸…ç†
python stage03_text_cleaning.py --src data/02_trad --dst data/03_clean

# 04 çµ±è¨ˆåˆ†æ
python stage04_data_statistics_analysis.py --src data/03_clean --report out/reports/stats.json

# 05 æ‘˜è¦ç”Ÿæˆï¼ˆé€é models/llm_model.pyï¼‰
python stage05_generate_summary.py --src data/03_clean --dst data/05_summaries --model llm_default

# 06 æ‘˜è¦è©•ä¼°ï¼ˆBERTScore/å¯æ“´å…… ROUGEï¼‰
python stage06_summary_evaluation_bertscore.py --src data/05_summaries --ref data/refs --out out/metrics/bertscore.csv

# 07 è³‡æ–™é›†åˆ‡åˆ†
python stage07_dataset_preparation.py --src data/03_clean --dst data/07_dataset --split 0.8 0.1 0.1

# 08 æ¨¡å‹è¨“ç·´ï¼ˆå¯é¸ï¼‰
python stage08_model_training.py --data data/07_dataset --out out/models/baseline
```

---

## ğŸ“œ License
**MIT License**ï¼ˆæœ¬ç¨‹å¼ç¢¼æ¡ç”¨ MITï¼›è³‡æ–™é›†æˆæ¬Šä¾ Kaggle/åŸå§‹æä¾›æ–¹è¦ç¯„ï¼‰

---

## ğŸ™ Acknowledgements
- Kaggle â€” *Categorised News Dataset from Fudan University*  
- é–‹æºç¤¾ç¾¤æ–¼ä¸­æ–‡ NLPã€é•·æ–‡æ‘˜è¦èˆ‡è©•ä¼°æŒ‡æ¨™ï¼ˆBERTScore/ROUGEï¼‰çš„è²¢ç»
